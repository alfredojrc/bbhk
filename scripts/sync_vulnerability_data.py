#!/usr/bin/env python3
"""
Data Synchronization Engineer - Vulnerability Data Sync
Updates Qdrant vector database with new vulnerability patterns and frameworks
"""

import json
import logging
import sqlite3
import requests
from datetime import datetime
from typing import List, Dict, Any
import os
import sys

# Logging setup
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class VulnerabilityDataSync:
    def __init__(self):
        self.qdrant_url = "http://localhost:6333"
        self.sqlite_db = ".swarm/memory.db"
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Tier 1 active vulnerabilities from ATTACK_VECTORS_AUGUST_2025.md
        self.tier1_vulnerabilities = [
            {
                "id": "chainlink_ace_policy_bypass",
                "title": "Chainlink ACE Policy Manager Bypass",
                "description": "Hybrid execution policy bypass in Chainlink's Automated Compliance Engine allowing policy enforcement inconsistencies between onchain and offchain verification",
                "severity": "critical",
                "bounty_range": "$200k-$500k",
                "status": "active",
                "launch_date": "2025-06-30",
                "difficulty": 7,
                "vector_type": "business_logic",
                "payload": "if (onchainPolicy.check() && offchainPolicy.verify()) { /* exploit inconsistencies */ }",
                "target": "Institutional compliance engine ($100T)",
                "tags": ["chainlink", "ace", "policy", "compliance", "hybrid", "business_logic"]
            },
            {
                "id": "chainlink_ace_multi_policy",
                "title": "Chainlink ACE Multi-layered Policy Conflicts", 
                "description": "Complex rule combination exploits triggering emergencyOverride inappropriately through jurisdiction + accreditation + sanctions rule conflicts",
                "severity": "high",
                "bounty_range": "$100k-$300k", 
                "status": "active",
                "launch_date": "2025-06-30",
                "difficulty": 7,
                "vector_type": "business_logic",
                "payload": "if ((jurisdiction && accreditation && !sanctions) || emergencyOverride)",
                "target": "Multi-layer compliance rules",
                "tags": ["chainlink", "ace", "policy", "rules", "emergency", "business_logic"]
            },
            {
                "id": "chainlink_ace_toctou",
                "title": "Chainlink ACE Cross-Chain TOCTOU",
                "description": "Time-of-check vs time-of-use vulnerabilities in cross-chain verification with message passing delay exploitation",
                "severity": "high", 
                "bounty_range": "$100k-$200k",
                "status": "active",
                "launch_date": "2025-06-30",
                "difficulty": 8,
                "vector_type": "race_condition",
                "payload": "/* exploit timing between cross-chain policy checks */",
                "target": "Cross-chain policy enforcement",
                "tags": ["chainlink", "ace", "toctou", "race_condition", "cross_chain"]
            },
            {
                "id": "chainlink_functions_oracle_poisoning",
                "title": "Chainlink Functions Oracle Data Poisoning",
                "description": "Number(Deno.args) without NaN/Infinity validation in functions-toolkit sandbox causing DoS and validation bypass",
                "severity": "critical",
                "bounty_range": "$50k-$200k",
                "status": "verified",
                "location": "functions-toolkit/src/simulateScript/deno-sandbox/sandbox.ts:204-208",
                "mainnet_address": "0x65Dcc24F8ff9e51F10DCc7Ed1e4e2A61e6E14bd6",
                "difficulty": 6,
                "vector_type": "input_validation",
                "success_rate": "60-70%",
                "tags": ["chainlink", "functions", "oracle", "input_validation", "deno", "sandbox"]
            }
        ]
        
        # Updated T.K.V.F. framework data
        self.tkvf_framework = {
            "name": "Technology Knowledge Verification Framework",
            "version": "2.0",
            "updated": "2025-08-25",
            "description": "Mandatory verification process to prevent false assumptions about technology before vulnerability research",
            "steps": [
                "STOP - Don't assume anything about the technology",
                "VERIFY - Run the 25-minute verification process", 
                "DOCUMENT - Update knowledge base with findings"
            ],
            "rules": [
                "ASSUME NOTHING - VERIFY EVERYTHING",
                "GitHub â‰  Production",
                "25 minutes of verification saves 25 hours of wasted research"
            ],
            "success_cases": [
                "Prevented Ondo T+2 false positive (tokens burned immediately)",
                "Prevented Chainlink External Adapters false positive (deprecated)",
                "Prevented Keystone Network false positive (no mainnet deployment)"
            ]
        }
        
        # D.I.E. standards updated
        self.die_standards = {
            "framework": "D.I.E. Framework",
            "version": "1.5", 
            "updated": "2025-08-25",
            "criteria": {
                "Demonstrable": "Working PoC required - must show actual exploitation",
                "Impactful": "Clear security impact with quantifiable damage potential",
                "Evidentiary": "Complete evidence including code, payloads, and impact proof"
            },
            "rejection_reasons": [
                "Theoretical vulnerabilities without PoC",
                "Low impact information disclosures",
                "Deprecated/testnet-only vulnerabilities"
            ]
        }

    def connect_qdrant(self) -> bool:
        """Test connection to Qdrant"""
        try:
            # Try base endpoint since /health might not exist
            response = requests.get(f"{self.qdrant_url}")
            if response.status_code == 200:
                logger.info("Qdrant connection successful")
                return True
            else:
                logger.error(f"Qdrant connection failed: {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"Failed to connect to Qdrant: {e}")
            return False

    def create_collection_if_not_exists(self, collection_name: str, vector_size: int = 1536):
        """Create Qdrant collection if it doesn't exist"""
        try:
            # Check if collection exists
            response = requests.get(f"{self.qdrant_url}/collections/{collection_name}")
            if response.status_code == 200:
                logger.info(f"Collection {collection_name} already exists")
                return True
                
            # Create collection
            config = {
                "vectors": {
                    "size": vector_size,
                    "distance": "Cosine"
                }
            }
            response = requests.put(
                f"{self.qdrant_url}/collections/{collection_name}",
                json=config
            )
            
            if response.status_code in [200, 201]:
                logger.info(f"Created collection: {collection_name}")
                return True
            else:
                logger.error(f"Failed to create collection {collection_name}: {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"Error creating collection {collection_name}: {e}")
            return False

    def generate_embedding_placeholder(self, text: str) -> List[float]:
        """Generate placeholder embedding (in production, use OpenAI or similar)"""
        # Simple hash-based embedding for demonstration
        import hashlib
        hash_obj = hashlib.md5(text.encode())
        hash_hex = hash_obj.hexdigest()
        
        # Convert to vector of floats (1536 dimensions for OpenAI compatibility)
        embedding = []
        for i in range(0, len(hash_hex), 2):
            val = int(hash_hex[i:i+2], 16) / 255.0  # Normalize to 0-1
            embedding.extend([val] * 48)  # Repeat to get 1536 dimensions
            if len(embedding) >= 1536:
                break
        
        # Ensure exactly 1536 dimensions
        while len(embedding) < 1536:
            embedding.append(0.0)
        
        # Validate vector length and content
        vector = embedding[:1536]
        if len(vector) != 1536:
            logger.warning(f"Vector length mismatch: {len(vector)} != 1536")
        
        return vector

    def update_vulnerability_patterns(self):
        """Update Qdrant with Tier 1 vulnerability patterns"""
        logger.info("Updating vulnerability patterns in Qdrant...")
        
        if not self.connect_qdrant():
            logger.error("Cannot connect to Qdrant, skipping update")
            return False
            
        # Create collection for vulnerability patterns
        if not self.create_collection_if_not_exists("tier1_vulnerabilities"):
            return False
            
        # Prepare points for insertion
        points = []
        for vuln in self.tier1_vulnerabilities:
            # Create searchable text from vulnerability data
            search_text = f"{vuln['title']} {vuln['description']} {' '.join(vuln['tags'])}"
            
            point = {
                "id": hash(vuln['id']) % (2**31),  # Convert to integer ID
                "vector": self.generate_embedding_placeholder(search_text),
                "payload": {
                    **vuln,
                    "sync_timestamp": self.timestamp,
                    "search_text": search_text
                }
            }
            points.append(point)
        
        # Upload points to Qdrant
        try:
            response = requests.put(
                f"{self.qdrant_url}/collections/tier1_vulnerabilities/points",
                json={"points": points}
            )
            
            if response.status_code == 200:
                logger.info(f"Successfully updated {len(points)} vulnerability patterns")
                return True
            else:
                logger.error(f"Failed to update vulnerability patterns: {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"Error updating vulnerability patterns: {e}")
            return False

    def update_framework_data(self):
        """Update T.K.V.F. and D.I.E. framework data"""
        logger.info("Updating framework data in Qdrant...")
        
        if not self.create_collection_if_not_exists("frameworks"):
            return False
            
        frameworks = [self.tkvf_framework, self.die_standards]
        points = []
        
        for idx, framework in enumerate(frameworks):
            search_text = f"{framework.get('name', '')} {framework.get('description', '')} {' '.join(map(str, framework.get('steps', [])))}"
            
            point = {
                "id": idx + 1000,  # Offset to avoid collision
                "vector": self.generate_embedding_placeholder(search_text),
                "payload": {
                    **framework,
                    "sync_timestamp": self.timestamp,
                    "search_text": search_text
                }
            }
            points.append(point)
        
        try:
            response = requests.put(
                f"{self.qdrant_url}/collections/frameworks/points",
                json={"points": points}
            )
            
            if response.status_code == 200:
                logger.info(f"Successfully updated framework data")
                return True
            else:
                logger.error(f"Failed to update framework data: {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"Error updating framework data: {e}")
            return False

    def update_sqlite_vulnerabilities(self):
        """Update SQLite database with new vulnerability data"""
        logger.info("Updating SQLite with vulnerability data...")
        
        try:
            conn = sqlite3.connect(self.sqlite_db)
            cursor = conn.cursor()
            
            # Update vulnerabilities table with existing schema
            for vuln in self.tier1_vulnerabilities:
                # Map to existing schema columns
                cursor.execute("""
                    INSERT OR REPLACE INTO vulnerabilities 
                    (type, severity, pattern, payout_min, payout_max, status, exploit_code, data, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    vuln['vector_type'],
                    vuln['severity'], 
                    vuln['title'],
                    int(vuln['bounty_range'].split('$')[1].split('k')[0]) * 1000 if 'k' in vuln['bounty_range'] else 0,
                    int(vuln['bounty_range'].split('-$')[1].split('k')[0]) * 1000 if '-$' in vuln['bounty_range'] and 'k' in vuln['bounty_range'] else 0,
                    vuln['status'],
                    vuln.get('payload', ''),
                    json.dumps(vuln),
                    datetime.now().isoformat()
                ))
            
            # Update policies table with frameworks
            cursor.execute("""
                INSERT OR REPLACE INTO policies (key, value, created_at)
                VALUES (?, ?, ?)
            """, ('tkvf_framework', json.dumps(self.tkvf_framework), datetime.now().isoformat()))
            
            cursor.execute("""
                INSERT OR REPLACE INTO policies (key, value, created_at)
                VALUES (?, ?, ?)  
            """, ('die_standards', json.dumps(self.die_standards), datetime.now().isoformat()))
            
            conn.commit()
            conn.close()
            
            logger.info("Successfully updated SQLite database")
            return True
            
        except Exception as e:
            logger.error(f"Error updating SQLite: {e}")
            return False

    def remove_outdated_information(self):
        """Remove outdated/inaccurate vulnerability information"""
        logger.info("Removing outdated information...")
        
        # Outdated vulnerabilities to remove/mark inactive
        outdated_patterns = [
            "Ondo Finance T+2 Settlement",  # FALSE POSITIVE - tokens burned immediately
            "Chainlink External Adapters", # DEPRECATED
            "Keystone Network"  # No mainnet deployment
        ]
        
        try:
            # Update SQLite to mark as inactive based on pattern matching
            conn = sqlite3.connect(self.sqlite_db)
            cursor = conn.cursor()
            
            for pattern in outdated_patterns:
                cursor.execute("""
                    UPDATE vulnerabilities 
                    SET status = 'inactive'
                    WHERE pattern LIKE ? OR type LIKE ?
                """, (f'%{pattern}%', f'%{pattern}%'))
            
            # Add documentation about removed items
            cursor.execute("""
                INSERT INTO policies (key, value, created_at)
                VALUES (?, ?, ?)
            """, ('outdated_vulnerabilities_removed', json.dumps({
                "timestamp": self.timestamp,
                "removed_patterns": outdated_patterns,
                "reason": "False positives or deprecated vulnerabilities identified through T.K.V.F. verification"
            }), datetime.now().isoformat()))
            
            conn.commit()
            conn.close()
            
            # Remove from Qdrant collections
            for collection in ["tier1_vulnerabilities", "bbhk_vulnerabilities"]:
                try:
                    for pattern in outdated_patterns:
                        point_id = hash(pattern) % (2**31)
                        requests.delete(f"{self.qdrant_url}/collections/{collection}/points/{point_id}")
                except Exception as e:
                    logger.warning(f"Could not remove {pattern} from {collection}: {e}")
            
            logger.info(f"Marked vulnerabilities matching {len(outdated_patterns)} patterns as inactive")
            return True
            
        except Exception as e:
            logger.error(f"Error removing outdated information: {e}")
            return False

    def generate_sync_report(self):
        """Generate data synchronization report"""
        report = {
            "sync_timestamp": self.timestamp,
            "operations_performed": {
                "qdrant_updates": {
                    "vulnerability_patterns": len(self.tier1_vulnerabilities),
                    "framework_data": 2,
                    "collections_updated": ["tier1_vulnerabilities", "frameworks"]
                },
                "sqlite_updates": {
                    "vulnerabilities_added": len(self.tier1_vulnerabilities),
                    "policies_updated": 2,
                    "outdated_removed": 3
                },
                "cleanup_operations": {
                    "inactive_vulns": 3,
                    "deprecated_removed": True
                }
            },
            "data_consistency_status": "synchronized",
            "tier1_vulnerabilities": self.tier1_vulnerabilities,
            "frameworks_updated": ["T.K.V.F. 2.0", "D.I.E. 1.5"],
            "next_sync_recommended": datetime.now().strftime("%Y-%m-%d"),
        }
        
        report_file = f"/home/kali/bbhk/reports/data_sync_report_{self.timestamp}.json"
        os.makedirs(os.path.dirname(report_file), exist_ok=True)
        
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
            
        logger.info(f"Sync report generated: {report_file}")
        return report

    def run_full_sync(self):
        """Execute full data synchronization"""
        logger.info("Starting full data synchronization...")
        
        success_count = 0
        total_operations = 5
        
        # Update Qdrant vector database
        if self.update_vulnerability_patterns():
            success_count += 1
            
        if self.update_framework_data():
            success_count += 1
            
        # Update SQLite database
        if self.update_sqlite_vulnerabilities():
            success_count += 1
            
        # Remove outdated information
        if self.remove_outdated_information():
            success_count += 1
            
        # Generate report
        report = self.generate_sync_report()
        success_count += 1
        
        logger.info(f"Synchronization completed: {success_count}/{total_operations} operations successful")
        
        return success_count == total_operations, report

def main():
    """Main execution function"""
    print("ðŸ¤– Data Synchronization Engineer - Vulnerability Data Sync")
    print("=" * 60)
    
    sync_engine = VulnerabilityDataSync()
    success, report = sync_engine.run_full_sync()
    
    if success:
        print("\nâœ… DATA SYNCHRONIZATION COMPLETED SUCCESSFULLY")
        print(f"ðŸ“Š Updated {len(sync_engine.tier1_vulnerabilities)} Tier 1 vulnerabilities")
        print(f"ðŸ”„ Synchronized T.K.V.F. and D.I.E. frameworks")
        print(f"ðŸ—‘ï¸ Removed 3 outdated/false positive entries")
        print(f"ðŸ“ Report generated: data_sync_report_{sync_engine.timestamp}.json")
    else:
        print("\nâŒ DATA SYNCHRONIZATION PARTIALLY FAILED")
        print("Check logs for detailed error information")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())